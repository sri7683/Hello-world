{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMU+i5fUIeezWHEbuIuAlKk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sri7683/Hello-world/blob/main/Disseratation_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kQw_-2F47hIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCBvhfaM7ahB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_1 = pd.read_csv(\"/content/drive/MyDrive/config/tables/EMBED_OpenData_clinical.csv\")\n",
        "df2 = pd.read_csv(\"/content/drive/MyDrive/config/tables/EMBED_OpenData_metadata_reduced.csv\")"
      ],
      "metadata": {
        "id": "ncVURb697evJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_clinical = df_1[['empi_anon','acc_anon','asses', 'tissueden',\n",
        "                          'desc','side','path_severity','numfind','total_L_find','total_R_find',\n",
        "                          'massshape','massmargin','massdens','calcfind','calcdistri','calcnumber']]\n",
        "\n",
        "df_metadata = df2[['anon_dicom_path','acc_anon','StudyDescription','SeriesDescription','FinalImageType','ImageLateralityFinal','ViewPosition','spot_mag','ROI_coords','num_roi']]\n"
      ],
      "metadata": {
        "id": "JTMHqQbr7i8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merge = pd.merge(df_metadata, df_clinical, on=['acc_anon'])\n",
        "\n",
        "\n",
        "print(df_merge.describe().T)\n",
        "df_merge.head(5)\n",
        ""
      ],
      "metadata": {
        "id": "XT5UqCHi7k93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merge.info()\n",
        "print(df_merge.isnull().sum())"
      ],
      "metadata": {
        "id": "U2n8swaF7m6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merge = df_merge.dropna(subset=['path_severity'])\n",
        "df_merge['path_severity'] = df_merge['path_severity'].astype(int)"
      ],
      "metadata": {
        "id": "NMIy1NnU7rjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merge['path_severity'].unique()\n",
        "sns.countplot(x=\"path_severity\", data=df_merge)"
      ],
      "metadata": {
        "id": "Fa2oBj6i7vNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merge['StudyDescription'].unique()"
      ],
      "metadata": {
        "id": "beF4DSxZ70pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merge['SeriesDescription'].unique()"
      ],
      "metadata": {
        "id": "QnTJ8IO074R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merge['asses'].unique()\n",
        "sns.countplot(x=\"asses\", data=df_merge)\n"
      ],
      "metadata": {
        "id": "lLLMu8Lr76oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=\"asses\", data=df_clinical)"
      ],
      "metadata": {
        "id": "FV44OVWy78yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# basic libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import glob\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "j_8jM35d8Amu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Images = '/content/drive/MyDrive/config/sample_data'\n",
        "# Trimming and replacing the path\n",
        "df_merge['anon_dicom_path'] = df_merge['anon_dicom_path'].str.replace(\"/mnt/NAS2/mammo/anon_dicom/cohort_1\", \"/content/drive/MyDrive/config/sample_data\")\n"
      ],
      "metadata": {
        "id": "zfCdsszg8ECN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merge.to_csv('/content/drive/MyDrive/config/tables/df_merge.csv', index=False)\n"
      ],
      "metadata": {
        "id": "nISeDs_V8Ifj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the index\n",
        "df_merge = df_merge.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "AK3m40-T8Kr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a sample path\n",
        "df_merge.loc[22723, 'anon_dicom_path']"
      ],
      "metadata": {
        "id": "t5LjuXO_8NC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we will now get the list of ROIs for each of these images. ROIs are structured as a list of lists, and each image\n",
        "# can have 0 to multiple ROIs. We will therefore parse the ROI list to expand it such that each row will contain one ROI.\n",
        "# If an image has multiple ROIs, this will result in multiple rows for that image in the resultant dataframe\n",
        "\n",
        "#define function\n",
        "def separate_roi(df):\n",
        "    df_list = []\n",
        "    for ind, row in df.iterrows():\n",
        "        path = row['anon_dicom_path']\n",
        "        roi_num = [int(s) for s in re.findall(r'\\b\\d+\\b', row['ROI_coords'])]\n",
        "        if len(roi_num)==4:\n",
        "            df_list.append([path, row['ROI_coords'], row['ROI_coords']])\n",
        "        else:\n",
        "            count = 0\n",
        "            roi = []\n",
        "            for i in roi_num:\n",
        "                count += 1\n",
        "                roi.append(i)\n",
        "                if count%4 == 0:\n",
        "                    df_list.append([path, row['ROI_coords'], \"((\"+str(roi[0])+\", \"+str(roi[1])+\", \"+str(roi[2])+\", \"+str(roi[3])+\"),)\"])\n",
        "                    roi = []\n",
        "    df_roi_sep = pd.DataFrame(df_list)\n",
        "    df_roi_sep.columns = ['anon_dicom_path','ROI_coords','ROI_separated']\n",
        "    df_cp = df.copy()\n",
        "    df_cp = df_cp.merge(df_roi_sep, how='left', on=['anon_dicom_path','ROI_coords'])\n",
        "    return df_cp"
      ],
      "metadata": {
        "id": "k8VS4YNc8PG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pylibjpeg"
      ],
      "metadata": {
        "id": "pqEcus2a8S9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pydicom\n",
        "import pylibjpeg\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib import pyplot as plt\n"
      ],
      "metadata": {
        "id": "Aqiw9lsw8TpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stats(df): #the function displays dataframe size, countings of unique patients and unique exams\n",
        "    print('Dataframe size: ' + str(df.shape))\n",
        "    try:\n",
        "        print('# patients: ' + str(df.empi_anon.nunique()))\n",
        "    except:\n",
        "        print('# patients: ' + str(df.empi_anon_x.nunique()))\n",
        "    print('# exams: ' + str(df.acc_anon.nunique()))"
      ],
      "metadata": {
        "id": "b1EPx4bB8VWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To export ROIs, filter the ones with ROIs\n",
        "df_cancer_ROI = df_merge.loc[df_merge.ROI_coords!='()']\n",
        "stats(df_cancer_ROI)\n",
        "\n",
        "# Separate multiple ROIs into individual rows\n",
        "df_cancer_ROI = separate_roi(df_cancer_ROI)\n",
        "stats(df_cancer_ROI)\n",
        "\n",
        "# Export to csv\n",
        "df_cancer_ROI.to_csv(\"BR0CancerROIs.csv\")"
      ],
      "metadata": {
        "id": "u1Hew1318ZFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cancer_ROI.ROI_coords"
      ],
      "metadata": {
        "id": "SiHv4Yoe8bUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_file_name = \"/content/drive/MyDrive/config/sample_data/10000879/1.2.842.113970.3.62.1.56868341.20180426.1095160/1.2.840.113684.2750825173.1524118967.4848.25046.1/1.2.826.0.1.3680043.8.498.12326784267688742524174894068105129442.dcm\""
      ],
      "metadata": {
        "id": "gonHekuc8dSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydicom pylibjpeg-libjpeg"
      ],
      "metadata": {
        "id": "zc3pArZT8f8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pydicom\n",
        "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
        "import numpy as np\n",
        "\n",
        "dcm = pydicom.dcmread(sample_file_name)\n",
        "pixel_data = dcm.pixel_array\n",
        "\n"
      ],
      "metadata": {
        "id": "IFDv5HTj8jmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in sample dicom file\n",
        "ds = pydicom.dcmread(sample_file_name)\n",
        "arr = ds.pixel_array\n",
        "\n",
        "# Flip the dicom file left to right, the flipping logic is included in the dcm to png file conversion code\n",
        "new_np_array = np.copy(arr)\n",
        "#define the width(w) and height(h) of the image\n",
        "h, w = arr.shape\n",
        "#make the image left-right\n",
        "for j in range(0,w):\n",
        "    for i in range(0,h):\n",
        "        new_np_array[i,j] = arr[i,w-1-j]"
      ],
      "metadata": {
        "id": "5wIToY7L8leQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pydicom\n",
        "import os"
      ],
      "metadata": {
        "id": "wAt0_s9a8nAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the directory containing the DICOM files\n",
        "dataset_dir = '/content/drive/MyDrive/config/sample_data/10000879'"
      ],
      "metadata": {
        "id": "LL2g0iV18rGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicom_files=[]\n",
        "# Recursively search for DICOM files\n",
        "for root, dirs, files in os.walk(dataset_dir):\n",
        "    for file in files:\n",
        "        if file.endswith('.dcm'):\n",
        "            dicom_files.append(os.path.join(root, file))"
      ],
      "metadata": {
        "id": "mw4COLqf8s2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read each DICOM file and extract the pixel data\n",
        "for file in dicom_files[:2]:\n",
        "    dcm = pydicom.dcmread(file)\n",
        "    pixel_data = dcm.pixel_array\n",
        "    print(pixel_data)"
      ],
      "metadata": {
        "id": "N1tZPy-_8tff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in sample dicom file\n",
        "ds = pydicom.dcmread(sample_file_name)\n",
        "arr = ds.pixel_array\n",
        "\n",
        "# Flip the dicom file left to right, the flipping logic is included in the dcm to png file conversion code\n",
        "new_np_array = np.copy(arr)\n",
        "#define the width(w) and height(h) of the image\n",
        "h, w = arr.shape\n",
        "#make the image left-right\n",
        "for j in range(0,w):\n",
        "    for i in range(0,h):\n",
        "        new_np_array[i,j] = arr[i,w-1-j]"
      ],
      "metadata": {
        "id": "unkIf3I58xnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the coordinates of ROI\n",
        "rois = [int(s) for s in re.findall(r'\\b\\d+\\b', sample_file_ROI)]\n",
        "y1, x1, y2, x2 = rois"
      ],
      "metadata": {
        "id": "Ue6LSTF-8yaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display ROI on image\n",
        "figure, ax = plt.subplots(1)\n",
        "rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1, edgecolor='r', facecolor='none')\n",
        "ax.imshow(new_np_array, cmap=\"gray\")\n",
        "ax.add_patch(rect)"
      ],
      "metadata": {
        "id": "yLil1eqq80eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "data = []\n",
        "\n",
        "# Traverse the main directory\n",
        "for root, dirs, files in os.walk('/content/drive/MyDrive/config/sample_data'):\n",
        "    for file in files:\n",
        "        if file.endswith('.dcm'):  # Modify the file extension if needed\n",
        "            image_path = os.path.join(root, file)\n",
        "            class_label = os.path.basename(os.path.dirname(image_path))\n",
        "            data.append({'image_path': image_path, 'class': class_label})\n",
        "\n",
        "# Create a DataFrame from the collected data\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "jtU6twDO82Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(df_merge['asses'].unique())\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Convert labels to categorical format\n",
        "df_merge['label'] = df_merge['asses'].astype('category').cat.codes\n",
        "labels = to_categorical(df_merge['label'], num_classes)\n"
      ],
      "metadata": {
        "id": "usv3PDMN84xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(df_merge['anon_dicom_path'], labels, test_size=0.2, stratify=labels)\n"
      ],
      "metadata": {
        "id": "dwRI5mrd87Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the image size and other parameters\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Define the data directory\n",
        "data_directory = '/content/drive/MyDrive/config/sample_data'\n",
        "\n",
        "# Load the dataframe containing image paths and labels\n",
        "df_merge = pd.read_csv('/content/drive/MyDrive/config/tables/df_merge.csv')  # Replace with the actual path to your dataframe file\n",
        "\n",
        "# Create the data generator\n",
        "data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "\n",
        "# Create data generator for image loading and preprocessing\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create data generator for image loading and preprocessing\n",
        "train_data_gen = datagen.flow_from_dataframe(\n",
        "   dataframe=df_merge,\n",
        "   x_col='anon_dicom_path',  # Replace with the actual column name\n",
        "   y_col='asses',\n",
        "   target_size=image_size,\n",
        "   classes=class_labels,\n",
        "   class_mode='categorical',\n",
        "   batch_size=batch_size,\n",
        "   subset='training'\n",
        ")\n",
        "\n",
        "test_data_gen = datagen.flow_from_dataframe(\n",
        "   dataframe=df_merge,\n",
        "   x_col='anon_dicom_path',  # Replace with the actual column name\n",
        "   y_col='asses',\n",
        "   target_size=image_size,\n",
        "   classes=class_labels,\n",
        "   class_mode='categorical',\n",
        "   batch_size=batch_size,\n",
        "   subset='validation'\n",
        ")\n"
      ],
      "metadata": {
        "id": "Zen2BxHk89Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "IchdCU2Y8_v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data_gen, validation_data=test_data_gen, epochs=10)\n"
      ],
      "metadata": {
        "id": "vUKoDE599Ddl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}